{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jbanGyXRrK8c"
      },
      "source": [
        "# Classification of Nigerian Traditional Attire\n",
        "\n",
        "This project classifies images of Nigerian ethnic groups using transfer learning with convolutional neural networks. We experiment with ResNet18, ResNet34, and EfficientNet to compare performance.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eK6cY2lSr90Q"
      },
      "source": [
        "### Downloading Data from Google Drive"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gi25IiC4zlRF",
        "outputId": "24a69d38-686e-4ec2-8f2b-0c540126f48d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "data_dir = '/content/drive/MyDrive/path_to/data_split'\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_DX2UcWWs_-R"
      },
      "source": [
        "### Unzipping the file"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "dzWzJNdDz-5o"
      },
      "outputs": [],
      "source": [
        "!unzip -q '/content/drive/MyDrive/nigerian_attire.zip' -d /content/"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r8V_ccfS042Q"
      },
      "source": [
        "### Importing Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "cxpnXvTB0oDG"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import torch\n",
        "import torchvision\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from torchvision import datasets, transforms, models\n",
        "from torch.utils.data import DataLoader\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "import numpy as np\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cLzYbTDK1QwJ"
      },
      "source": [
        "### Data Preparation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LLvYwE4RAV1Z",
        "outputId": "0270661c-4230-4b50-990b-fcee2adb7fae"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Dataset split complete.\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import shutil\n",
        "import random\n",
        "\n",
        "def split_dataset(source_dir, dest_dir, train_ratio=0.8, val_ratio=0.1, test_ratio=0.1):\n",
        "    assert train_ratio + val_ratio + test_ratio == 1.0, \"Ratios must sum to 1.\"\n",
        "\n",
        "    # Create destination folders\n",
        "    for split in ['train', 'val', 'test']:\n",
        "        split_path = os.path.join(dest_dir, split)\n",
        "        os.makedirs(split_path, exist_ok=True)\n",
        "\n",
        "    # Process each class folder\n",
        "    classes = [d for d in os.listdir(source_dir) if os.path.isdir(os.path.join(source_dir, d))]\n",
        "\n",
        "    for cls in classes:\n",
        "        cls_path = os.path.join(source_dir, cls)\n",
        "        images = os.listdir(cls_path)\n",
        "        random.shuffle(images)\n",
        "\n",
        "        train_cutoff = int(train_ratio * len(images))\n",
        "        val_cutoff = int((train_ratio + val_ratio) * len(images))\n",
        "\n",
        "        split_sets = {\n",
        "            'train': images[:train_cutoff],\n",
        "            'val': images[train_cutoff:val_cutoff],\n",
        "            'test': images[val_cutoff:]\n",
        "        }\n",
        "\n",
        "        for split, split_images in split_sets.items():\n",
        "            split_dir = os.path.join(dest_dir, split, cls)\n",
        "            os.makedirs(split_dir, exist_ok=True)\n",
        "            for img in split_images:\n",
        "                src = os.path.join(cls_path, img)\n",
        "                dst = os.path.join(split_dir, img)\n",
        "                shutil.copy2(src, dst)\n",
        "\n",
        "    print(\"✅ Dataset split complete.\")\n",
        "\n",
        "# Usage\n",
        "split_dataset('nigerian_attire', 'data_split', train_ratio=0.8, val_ratio=0.1, test_ratio=0.1)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ei-Rft12uDay"
      },
      "source": [
        "### Data Transforms and Loaders"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NFapP8ykAp5z"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import random\n",
        "import numpy as np\n",
        "import torch\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data import DataLoader, WeightedRandomSampler\n",
        "from torchvision import datasets\n",
        "\n",
        "# ✅ Set seed for everything\n",
        "def set_seed(seed=42):\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed(seed)\n",
        "    torch.cuda.manual_seed_all(seed)  # if using multi-GPU\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "    torch.backends.cudnn.benchmark = False\n",
        "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
        "\n",
        "set_seed(42)\n",
        "\n",
        "# ✅ Define generator for reproducible DataLoader shuffling\n",
        "g = torch.Generator()\n",
        "g.manual_seed(42)\n",
        "\n",
        "# ✅ Data Transforms\n",
        "data_transforms = {\n",
        "    'train': transforms.Compose([\n",
        "        transforms.Resize((224, 224)),\n",
        "        transforms.RandomHorizontalFlip(),  # Has randomness\n",
        "        transforms.ToTensor(),\n",
        "    ]),\n",
        "    'val': transforms.Compose([\n",
        "        transforms.Resize((224, 224)),\n",
        "        transforms.ToTensor(),\n",
        "    ]),\n",
        "    'test': transforms.Compose([\n",
        "        transforms.Resize((224, 224)),\n",
        "        transforms.ToTensor(),\n",
        "    ]),\n",
        "}\n",
        "\n",
        "# ✅ Load datasets\n",
        "data_dir = 'data_split'\n",
        "image_datasets = {x: datasets.ImageFolder(os.path.join(data_dir, x), data_transforms[x])\n",
        "                  for x in ['train', 'val', 'test']}\n",
        "\n",
        "# ✅ Prepare WeightedRandomSampler for class balancing in training\n",
        "train_targets = [label for _, label in image_datasets['train'].imgs]\n",
        "class_counts = torch.tensor([train_targets.count(i) for i in range(len(set(train_targets)))], dtype=torch.float)\n",
        "class_weights = 1. / class_counts\n",
        "sample_weights = [class_weights[label] for label in train_targets]\n",
        "sampler = WeightedRandomSampler(weights=sample_weights, num_samples=len(sample_weights), replacement=True)\n",
        "\n",
        "# ✅ Create DataLoaders\n",
        "dataloaders = {\n",
        "    'train': DataLoader(image_datasets['train'], batch_size=32, sampler=sampler,\n",
        "                        num_workers=0, worker_init_fn=lambda _: set_seed(42), generator=g),\n",
        "    'val': DataLoader(image_datasets['val'], batch_size=32, shuffle=False,\n",
        "                      num_workers=0, worker_init_fn=lambda _: set_seed(42), generator=g),\n",
        "    'test': DataLoader(image_datasets['test'], batch_size=32, shuffle=False,\n",
        "                       num_workers=0, worker_init_fn=lambda _: set_seed(42), generator=g),\n",
        "}\n",
        "\n",
        "# ✅ Class names and device\n",
        "class_names = image_datasets['train'].classes\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FSYtsVGJ1_8J"
      },
      "source": [
        "### Model Definition (Pretrained EfficientNet)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "87DlzZPxTRYY",
        "outputId": "1351fa35-2386-46c9-9555-2f2e03feebfe"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting efficientnet_pytorch\n",
            "  Downloading efficientnet_pytorch-0.7.1.tar.gz (21 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (from efficientnet_pytorch) (2.6.0+cu124)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch->efficientnet_pytorch) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch->efficientnet_pytorch) (4.13.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch->efficientnet_pytorch) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch->efficientnet_pytorch) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch->efficientnet_pytorch) (2025.3.2)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch->efficientnet_pytorch)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch->efficientnet_pytorch)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch->efficientnet_pytorch)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch->efficientnet_pytorch)\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch->efficientnet_pytorch)\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch->efficientnet_pytorch)\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch->efficientnet_pytorch)\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch->efficientnet_pytorch)\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch->efficientnet_pytorch)\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch->efficientnet_pytorch) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch->efficientnet_pytorch) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->efficientnet_pytorch) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch->efficientnet_pytorch)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch->efficientnet_pytorch) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch->efficientnet_pytorch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch->efficientnet_pytorch) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch->efficientnet_pytorch) (3.0.2)\n",
            "Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m125.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m94.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m63.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m20.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m39.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: efficientnet_pytorch\n",
            "  Building wheel for efficientnet_pytorch (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for efficientnet_pytorch: filename=efficientnet_pytorch-0.7.1-py3-none-any.whl size=16426 sha256=fb39f85bf59883beeb09c2fa8ddd4e1c5b39abf50c3a58ba531aeef764c18810\n",
            "  Stored in directory: /root/.cache/pip/wheels/8b/6f/9b/231a832f811ab6ebb1b32455b177ffc6b8b1cd8de19de70c09\n",
            "Successfully built efficientnet_pytorch\n",
            "Installing collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, efficientnet_pytorch\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "Successfully installed efficientnet_pytorch-0.7.1 nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127\n"
          ]
        }
      ],
      "source": [
        "!pip install efficientnet_pytorch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RiVcJkR52A6y",
        "outputId": "4974f73b-5f31-497d-ad2f-bdce454ce64c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loaded pretrained weights for efficientnet-b0\n"
          ]
        }
      ],
      "source": [
        "from efficientnet_pytorch import EfficientNet\n",
        "\n",
        "# Load pre-trained EfficientNet-B0\n",
        "model = EfficientNet.from_pretrained('efficientnet-b0')\n",
        "\n",
        "# Replace the classifier for your number of classes\n",
        "num_ftrs = model._fc.in_features\n",
        "model._fc = nn.Linear(num_ftrs, len(class_names))\n",
        "\n",
        "model = model.to(device)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "By4uhMl42Mlc"
      },
      "source": [
        "### Loss, Optimizer, and Class Weights"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "N4gFPaNo2Q_S"
      },
      "outputs": [],
      "source": [
        "# Optional: Use class weights to handle imbalance\n",
        "class_counts = torch.tensor([len([label for _, label in image_datasets['train'] if label == i]) for i in range(len(class_names))])\n",
        "class_weights = 1. / class_counts.float()\n",
        "class_weights = class_weights.to(device)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss(weight=class_weights)\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "# Learning Rate Scheduler\n",
        "lr_scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=5, gamma=0.1)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VQTR4YCX2YPx"
      },
      "source": [
        "### Training Loop with Early Stopping"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qIRaVh9b2dSF",
        "outputId": "2d9e4526-b91f-46e7-f705-ca4f264f24a6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/10, Loss: 28.9715, Val Accuracy: 54.16%\n",
            "Epoch 2/10, Loss: 12.2483, Val Accuracy: 77.61%\n",
            "Epoch 3/10, Loss: 6.3662, Val Accuracy: 78.89%\n",
            "Epoch 4/10, Loss: 5.7048, Val Accuracy: 84.01%\n",
            "Epoch 5/10, Loss: 5.9257, Val Accuracy: 73.99%\n",
            "Epoch 6/10, Loss: 4.5509, Val Accuracy: 89.13%\n",
            "Epoch 7/10, Loss: 3.0777, Val Accuracy: 94.46%\n",
            "Epoch 8/10, Loss: 1.9803, Val Accuracy: 97.23%\n",
            "Epoch 9/10, Loss: 1.8058, Val Accuracy: 97.65%\n",
            "Epoch 10/10, Loss: 1.7947, Val Accuracy: 97.87%\n"
          ]
        }
      ],
      "source": [
        "num_epochs = 10\n",
        "patience = 5\n",
        "best_accuracy = 0.0\n",
        "epochs_no_improve = 0\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "\n",
        "    for inputs, labels in dataloaders['train']:\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item()\n",
        "\n",
        "    # Validation\n",
        "    model.eval()\n",
        "    correct, total = 0, 0\n",
        "    with torch.no_grad():\n",
        "        for inputs, labels in dataloaders['val']:\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "            outputs = model(inputs)\n",
        "            _, preds = torch.max(outputs, 1)\n",
        "            correct += (preds == labels).sum().item()\n",
        "            total += labels.size(0)\n",
        "\n",
        "    accuracy = 100 * correct / total\n",
        "    print(f\"Epoch {epoch+1}/{num_epochs}, Loss: {running_loss:.4f}, Val Accuracy: {accuracy:.2f}%\")\n",
        "\n",
        "    if accuracy > best_accuracy:\n",
        "        best_accuracy = accuracy\n",
        "        torch.save(model.state_dict(), 'best_model.pth')\n",
        "        epochs_no_improve = 0\n",
        "    # else:\n",
        "    #     epochs_no_improve += 1\n",
        "    #     if epochs_no_improve == patience:\n",
        "    #         print(\"Early stopping!\")\n",
        "    #         break\n",
        "\n",
        "    lr_scheduler.step()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1MttVzJ42q45"
      },
      "source": [
        "### Test the Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EbnFR2pi2t64",
        "outputId": "dfd94523-1443-492a-cfdd-28a9e6b2c4ba"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipykernel_6818/663958204.py:2: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  model.load_state_dict(torch.load('best_model.pth'))\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test Accuracy: 97.63%\n"
          ]
        }
      ],
      "source": [
        "# Load best model\n",
        "model.load_state_dict(torch.load('best_model.pth'))\n",
        "model.eval()\n",
        "\n",
        "correct, total = 0, 0\n",
        "all_preds = []\n",
        "all_labels = []\n",
        "\n",
        "with torch.no_grad():\n",
        "    for inputs, labels in dataloaders['test']:\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "        outputs = model(inputs)\n",
        "        _, preds = torch.max(outputs, 1)\n",
        "        correct += (preds == labels).sum().item()\n",
        "        total += labels.size(0)\n",
        "        all_preds.extend(preds.cpu().numpy())\n",
        "        all_labels.extend(labels.cpu().numpy())\n",
        "\n",
        "test_accuracy = 100 * correct / total\n",
        "print(f\"Test Accuracy: {test_accuracy:.2f}%\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "irQicdXK20ok"
      },
      "source": [
        "### Confusion Matrix and Classification Report"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 909
        },
        "id": "1neZZ7C-21X-",
        "outputId": "b55aaae4-8335-4458-d35c-0082c766df60"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 1000x800 with 2 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "      fulani       0.96      0.96      0.96        72\n",
            "       hausa       0.96      0.96      0.96        68\n",
            "        igbo       0.99      1.00      0.99        73\n",
            "      yoruba       1.00      0.99      0.99        82\n",
            "\n",
            "    accuracy                           0.98       295\n",
            "   macro avg       0.98      0.98      0.98       295\n",
            "weighted avg       0.98      0.98      0.98       295\n",
            "\n"
          ]
        }
      ],
      "source": [
        "cm = confusion_matrix(all_labels, all_preds)\n",
        "plt.figure(figsize=(10, 8))\n",
        "sns.heatmap(cm, annot=True, fmt='d', xticklabels=class_names, yticklabels=class_names, cmap='Blues')\n",
        "plt.xlabel('Predicted')\n",
        "plt.ylabel('Actual')\n",
        "plt.title('Confusion Matrix')\n",
        "plt.show()\n",
        "\n",
        "print(classification_report(all_labels, all_preds, target_names=class_names))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZTlTVcjX47fb"
      },
      "source": [
        "### Saving the Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Saving (more portable way)\n",
        "torch.save(model.state_dict(), 'efficientnetb0_weights.pth')\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Loadiing the Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipykernel_6818/1310851247.py:10: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  state_dict = torch.load('efficientnetb0_weights.pth', map_location='cpu')\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "EfficientNet(\n",
              "  (features): Sequential(\n",
              "    (0): Conv2dNormActivation(\n",
              "      (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (2): SiLU(inplace=True)\n",
              "    )\n",
              "    (1): Sequential(\n",
              "      (0): MBConv(\n",
              "        (block): Sequential(\n",
              "          (0): Conv2dNormActivation(\n",
              "            (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
              "            (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (2): SiLU(inplace=True)\n",
              "          )\n",
              "          (1): SqueezeExcitation(\n",
              "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
              "            (fc1): Conv2d(32, 8, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (fc2): Conv2d(8, 32, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (activation): SiLU(inplace=True)\n",
              "            (scale_activation): Sigmoid()\n",
              "          )\n",
              "          (2): Conv2dNormActivation(\n",
              "            (0): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "        )\n",
              "        (stochastic_depth): StochasticDepth(p=0.0, mode=row)\n",
              "      )\n",
              "    )\n",
              "    (2): Sequential(\n",
              "      (0): MBConv(\n",
              "        (block): Sequential(\n",
              "          (0): Conv2dNormActivation(\n",
              "            (0): Conv2d(16, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (2): SiLU(inplace=True)\n",
              "          )\n",
              "          (1): Conv2dNormActivation(\n",
              "            (0): Conv2d(96, 96, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=96, bias=False)\n",
              "            (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (2): SiLU(inplace=True)\n",
              "          )\n",
              "          (2): SqueezeExcitation(\n",
              "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
              "            (fc1): Conv2d(96, 4, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (fc2): Conv2d(4, 96, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (activation): SiLU(inplace=True)\n",
              "            (scale_activation): Sigmoid()\n",
              "          )\n",
              "          (3): Conv2dNormActivation(\n",
              "            (0): Conv2d(96, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (1): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "        )\n",
              "        (stochastic_depth): StochasticDepth(p=0.0125, mode=row)\n",
              "      )\n",
              "      (1): MBConv(\n",
              "        (block): Sequential(\n",
              "          (0): Conv2dNormActivation(\n",
              "            (0): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (2): SiLU(inplace=True)\n",
              "          )\n",
              "          (1): Conv2dNormActivation(\n",
              "            (0): Conv2d(144, 144, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=144, bias=False)\n",
              "            (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (2): SiLU(inplace=True)\n",
              "          )\n",
              "          (2): SqueezeExcitation(\n",
              "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
              "            (fc1): Conv2d(144, 6, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (fc2): Conv2d(6, 144, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (activation): SiLU(inplace=True)\n",
              "            (scale_activation): Sigmoid()\n",
              "          )\n",
              "          (3): Conv2dNormActivation(\n",
              "            (0): Conv2d(144, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (1): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "        )\n",
              "        (stochastic_depth): StochasticDepth(p=0.025, mode=row)\n",
              "      )\n",
              "    )\n",
              "    (3): Sequential(\n",
              "      (0): MBConv(\n",
              "        (block): Sequential(\n",
              "          (0): Conv2dNormActivation(\n",
              "            (0): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (2): SiLU(inplace=True)\n",
              "          )\n",
              "          (1): Conv2dNormActivation(\n",
              "            (0): Conv2d(144, 144, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), groups=144, bias=False)\n",
              "            (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (2): SiLU(inplace=True)\n",
              "          )\n",
              "          (2): SqueezeExcitation(\n",
              "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
              "            (fc1): Conv2d(144, 6, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (fc2): Conv2d(6, 144, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (activation): SiLU(inplace=True)\n",
              "            (scale_activation): Sigmoid()\n",
              "          )\n",
              "          (3): Conv2dNormActivation(\n",
              "            (0): Conv2d(144, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (1): BatchNorm2d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "        )\n",
              "        (stochastic_depth): StochasticDepth(p=0.037500000000000006, mode=row)\n",
              "      )\n",
              "      (1): MBConv(\n",
              "        (block): Sequential(\n",
              "          (0): Conv2dNormActivation(\n",
              "            (0): Conv2d(40, 240, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (1): BatchNorm2d(240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (2): SiLU(inplace=True)\n",
              "          )\n",
              "          (1): Conv2dNormActivation(\n",
              "            (0): Conv2d(240, 240, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=240, bias=False)\n",
              "            (1): BatchNorm2d(240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (2): SiLU(inplace=True)\n",
              "          )\n",
              "          (2): SqueezeExcitation(\n",
              "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
              "            (fc1): Conv2d(240, 10, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (fc2): Conv2d(10, 240, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (activation): SiLU(inplace=True)\n",
              "            (scale_activation): Sigmoid()\n",
              "          )\n",
              "          (3): Conv2dNormActivation(\n",
              "            (0): Conv2d(240, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (1): BatchNorm2d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "        )\n",
              "        (stochastic_depth): StochasticDepth(p=0.05, mode=row)\n",
              "      )\n",
              "    )\n",
              "    (4): Sequential(\n",
              "      (0): MBConv(\n",
              "        (block): Sequential(\n",
              "          (0): Conv2dNormActivation(\n",
              "            (0): Conv2d(40, 240, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (1): BatchNorm2d(240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (2): SiLU(inplace=True)\n",
              "          )\n",
              "          (1): Conv2dNormActivation(\n",
              "            (0): Conv2d(240, 240, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=240, bias=False)\n",
              "            (1): BatchNorm2d(240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (2): SiLU(inplace=True)\n",
              "          )\n",
              "          (2): SqueezeExcitation(\n",
              "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
              "            (fc1): Conv2d(240, 10, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (fc2): Conv2d(10, 240, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (activation): SiLU(inplace=True)\n",
              "            (scale_activation): Sigmoid()\n",
              "          )\n",
              "          (3): Conv2dNormActivation(\n",
              "            (0): Conv2d(240, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (1): BatchNorm2d(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "        )\n",
              "        (stochastic_depth): StochasticDepth(p=0.0625, mode=row)\n",
              "      )\n",
              "      (1): MBConv(\n",
              "        (block): Sequential(\n",
              "          (0): Conv2dNormActivation(\n",
              "            (0): Conv2d(80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (2): SiLU(inplace=True)\n",
              "          )\n",
              "          (1): Conv2dNormActivation(\n",
              "            (0): Conv2d(480, 480, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=480, bias=False)\n",
              "            (1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (2): SiLU(inplace=True)\n",
              "          )\n",
              "          (2): SqueezeExcitation(\n",
              "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
              "            (fc1): Conv2d(480, 20, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (fc2): Conv2d(20, 480, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (activation): SiLU(inplace=True)\n",
              "            (scale_activation): Sigmoid()\n",
              "          )\n",
              "          (3): Conv2dNormActivation(\n",
              "            (0): Conv2d(480, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (1): BatchNorm2d(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "        )\n",
              "        (stochastic_depth): StochasticDepth(p=0.07500000000000001, mode=row)\n",
              "      )\n",
              "      (2): MBConv(\n",
              "        (block): Sequential(\n",
              "          (0): Conv2dNormActivation(\n",
              "            (0): Conv2d(80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (2): SiLU(inplace=True)\n",
              "          )\n",
              "          (1): Conv2dNormActivation(\n",
              "            (0): Conv2d(480, 480, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=480, bias=False)\n",
              "            (1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (2): SiLU(inplace=True)\n",
              "          )\n",
              "          (2): SqueezeExcitation(\n",
              "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
              "            (fc1): Conv2d(480, 20, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (fc2): Conv2d(20, 480, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (activation): SiLU(inplace=True)\n",
              "            (scale_activation): Sigmoid()\n",
              "          )\n",
              "          (3): Conv2dNormActivation(\n",
              "            (0): Conv2d(480, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (1): BatchNorm2d(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "        )\n",
              "        (stochastic_depth): StochasticDepth(p=0.08750000000000001, mode=row)\n",
              "      )\n",
              "    )\n",
              "    (5): Sequential(\n",
              "      (0): MBConv(\n",
              "        (block): Sequential(\n",
              "          (0): Conv2dNormActivation(\n",
              "            (0): Conv2d(80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (2): SiLU(inplace=True)\n",
              "          )\n",
              "          (1): Conv2dNormActivation(\n",
              "            (0): Conv2d(480, 480, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=480, bias=False)\n",
              "            (1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (2): SiLU(inplace=True)\n",
              "          )\n",
              "          (2): SqueezeExcitation(\n",
              "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
              "            (fc1): Conv2d(480, 20, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (fc2): Conv2d(20, 480, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (activation): SiLU(inplace=True)\n",
              "            (scale_activation): Sigmoid()\n",
              "          )\n",
              "          (3): Conv2dNormActivation(\n",
              "            (0): Conv2d(480, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (1): BatchNorm2d(112, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "        )\n",
              "        (stochastic_depth): StochasticDepth(p=0.1, mode=row)\n",
              "      )\n",
              "      (1): MBConv(\n",
              "        (block): Sequential(\n",
              "          (0): Conv2dNormActivation(\n",
              "            (0): Conv2d(112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (1): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (2): SiLU(inplace=True)\n",
              "          )\n",
              "          (1): Conv2dNormActivation(\n",
              "            (0): Conv2d(672, 672, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=672, bias=False)\n",
              "            (1): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (2): SiLU(inplace=True)\n",
              "          )\n",
              "          (2): SqueezeExcitation(\n",
              "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
              "            (fc1): Conv2d(672, 28, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (fc2): Conv2d(28, 672, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (activation): SiLU(inplace=True)\n",
              "            (scale_activation): Sigmoid()\n",
              "          )\n",
              "          (3): Conv2dNormActivation(\n",
              "            (0): Conv2d(672, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (1): BatchNorm2d(112, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "        )\n",
              "        (stochastic_depth): StochasticDepth(p=0.1125, mode=row)\n",
              "      )\n",
              "      (2): MBConv(\n",
              "        (block): Sequential(\n",
              "          (0): Conv2dNormActivation(\n",
              "            (0): Conv2d(112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (1): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (2): SiLU(inplace=True)\n",
              "          )\n",
              "          (1): Conv2dNormActivation(\n",
              "            (0): Conv2d(672, 672, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=672, bias=False)\n",
              "            (1): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (2): SiLU(inplace=True)\n",
              "          )\n",
              "          (2): SqueezeExcitation(\n",
              "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
              "            (fc1): Conv2d(672, 28, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (fc2): Conv2d(28, 672, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (activation): SiLU(inplace=True)\n",
              "            (scale_activation): Sigmoid()\n",
              "          )\n",
              "          (3): Conv2dNormActivation(\n",
              "            (0): Conv2d(672, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (1): BatchNorm2d(112, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "        )\n",
              "        (stochastic_depth): StochasticDepth(p=0.125, mode=row)\n",
              "      )\n",
              "    )\n",
              "    (6): Sequential(\n",
              "      (0): MBConv(\n",
              "        (block): Sequential(\n",
              "          (0): Conv2dNormActivation(\n",
              "            (0): Conv2d(112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (1): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (2): SiLU(inplace=True)\n",
              "          )\n",
              "          (1): Conv2dNormActivation(\n",
              "            (0): Conv2d(672, 672, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), groups=672, bias=False)\n",
              "            (1): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (2): SiLU(inplace=True)\n",
              "          )\n",
              "          (2): SqueezeExcitation(\n",
              "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
              "            (fc1): Conv2d(672, 28, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (fc2): Conv2d(28, 672, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (activation): SiLU(inplace=True)\n",
              "            (scale_activation): Sigmoid()\n",
              "          )\n",
              "          (3): Conv2dNormActivation(\n",
              "            (0): Conv2d(672, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "        )\n",
              "        (stochastic_depth): StochasticDepth(p=0.1375, mode=row)\n",
              "      )\n",
              "      (1): MBConv(\n",
              "        (block): Sequential(\n",
              "          (0): Conv2dNormActivation(\n",
              "            (0): Conv2d(192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (1): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (2): SiLU(inplace=True)\n",
              "          )\n",
              "          (1): Conv2dNormActivation(\n",
              "            (0): Conv2d(1152, 1152, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1152, bias=False)\n",
              "            (1): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (2): SiLU(inplace=True)\n",
              "          )\n",
              "          (2): SqueezeExcitation(\n",
              "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
              "            (fc1): Conv2d(1152, 48, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (fc2): Conv2d(48, 1152, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (activation): SiLU(inplace=True)\n",
              "            (scale_activation): Sigmoid()\n",
              "          )\n",
              "          (3): Conv2dNormActivation(\n",
              "            (0): Conv2d(1152, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "        )\n",
              "        (stochastic_depth): StochasticDepth(p=0.15000000000000002, mode=row)\n",
              "      )\n",
              "      (2): MBConv(\n",
              "        (block): Sequential(\n",
              "          (0): Conv2dNormActivation(\n",
              "            (0): Conv2d(192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (1): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (2): SiLU(inplace=True)\n",
              "          )\n",
              "          (1): Conv2dNormActivation(\n",
              "            (0): Conv2d(1152, 1152, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1152, bias=False)\n",
              "            (1): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (2): SiLU(inplace=True)\n",
              "          )\n",
              "          (2): SqueezeExcitation(\n",
              "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
              "            (fc1): Conv2d(1152, 48, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (fc2): Conv2d(48, 1152, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (activation): SiLU(inplace=True)\n",
              "            (scale_activation): Sigmoid()\n",
              "          )\n",
              "          (3): Conv2dNormActivation(\n",
              "            (0): Conv2d(1152, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "        )\n",
              "        (stochastic_depth): StochasticDepth(p=0.1625, mode=row)\n",
              "      )\n",
              "      (3): MBConv(\n",
              "        (block): Sequential(\n",
              "          (0): Conv2dNormActivation(\n",
              "            (0): Conv2d(192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (1): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (2): SiLU(inplace=True)\n",
              "          )\n",
              "          (1): Conv2dNormActivation(\n",
              "            (0): Conv2d(1152, 1152, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1152, bias=False)\n",
              "            (1): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (2): SiLU(inplace=True)\n",
              "          )\n",
              "          (2): SqueezeExcitation(\n",
              "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
              "            (fc1): Conv2d(1152, 48, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (fc2): Conv2d(48, 1152, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (activation): SiLU(inplace=True)\n",
              "            (scale_activation): Sigmoid()\n",
              "          )\n",
              "          (3): Conv2dNormActivation(\n",
              "            (0): Conv2d(1152, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "        )\n",
              "        (stochastic_depth): StochasticDepth(p=0.17500000000000002, mode=row)\n",
              "      )\n",
              "    )\n",
              "    (7): Sequential(\n",
              "      (0): MBConv(\n",
              "        (block): Sequential(\n",
              "          (0): Conv2dNormActivation(\n",
              "            (0): Conv2d(192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (1): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (2): SiLU(inplace=True)\n",
              "          )\n",
              "          (1): Conv2dNormActivation(\n",
              "            (0): Conv2d(1152, 1152, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1152, bias=False)\n",
              "            (1): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (2): SiLU(inplace=True)\n",
              "          )\n",
              "          (2): SqueezeExcitation(\n",
              "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
              "            (fc1): Conv2d(1152, 48, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (fc2): Conv2d(48, 1152, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (activation): SiLU(inplace=True)\n",
              "            (scale_activation): Sigmoid()\n",
              "          )\n",
              "          (3): Conv2dNormActivation(\n",
              "            (0): Conv2d(1152, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (1): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "        )\n",
              "        (stochastic_depth): StochasticDepth(p=0.1875, mode=row)\n",
              "      )\n",
              "    )\n",
              "    (8): Conv2dNormActivation(\n",
              "      (0): Conv2d(320, 1280, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (1): BatchNorm2d(1280, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (2): SiLU(inplace=True)\n",
              "    )\n",
              "  )\n",
              "  (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
              "  (classifier): Sequential(\n",
              "    (0): Dropout(p=0.2, inplace=True)\n",
              "    (1): Linear(in_features=1280, out_features=4, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "execution_count": 26,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from torchvision.models import efficientnet_b0\n",
        "import torch.nn as nn\n",
        "import torch\n",
        "\n",
        "# Recreate model architecture\n",
        "model = efficientnet_b0(weights=None)  # no warning\n",
        "model.classifier[1] = nn.Linear(model.classifier[1].in_features, 4)\n",
        "\n",
        "# Load the weights\n",
        "state_dict = torch.load('efficientnetb0_weights.pth', map_location='cpu')\n",
        "model.load_state_dict(state_dict)\n",
        "model.eval()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/home/naziruai/miniconda3/envs/deep_learning/lib/python3.12/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/home/naziruai/miniconda3/envs/deep_learning/lib/python3.12/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n",
            "  warnings.warn(msg)\n",
            "/home/naziruai/Desktop/arewaDS_workspace/DL-Capstone-Project-Group-9/ethnic_classifier_gradio_app.py:22: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  model.load_state_dict(torch.load('efficientnetb0_weights.pth', map_location='cpu'))  # Your saved state_dict path\n",
            "* Running on local URL:  http://127.0.0.1:7860\n",
            "* To create a public link, set `share=True` in `launch()`.\n",
            "Logits: tensor([[-0.0231, -0.0222,  0.0064, -0.0273]])\n",
            "Probabilities: tensor([[0.2483, 0.2486, 0.2558, 0.2473]])\n",
            "Created dataset file at: .gradio/flagged/dataset1.csv\n",
            "Keyboard interruption in main thread... closing server.\n",
            "^C\n",
            "Traceback (most recent call last):\n",
            "  File \"/home/naziruai/miniconda3/envs/deep_learning/lib/python3.12/site-packages/gradio/blocks.py\", line 3075, in block_thread\n",
            "    time.sleep(0.1)\n",
            "KeyboardInterrupt\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/home/naziruai/Desktop/arewaDS_workspace/DL-Capstone-Project-Group-9/ethnic_classifier_gradio_app.py\", line 50, in <module>\n",
            "    gr.Interface(fn=predict, inputs=\"image\", outputs=\"label\", title=\"Ethnic Group Classifier\").launch()\n",
            "  File \"/home/naziruai/miniconda3/envs/deep_learning/lib/python3.12/site-packages/gradio/blocks.py\", line 2981, in launch\n",
            "    self.block_thread()\n",
            "  File \"/home/naziruai/miniconda3/envs/deep_learning/lib/python3.12/site-packages/gradio/blocks.py\", line 3079, in block_thread\n",
            "    self.server.close()\n",
            "  File \"/home/naziruai/miniconda3/envs/deep_learning/lib/python3.12/site-packages/gradio/http_server.py\", line 69, in close\n",
            "    self.thread.join(timeout=5)\n",
            "  File \"/home/naziruai/miniconda3/envs/deep_learning/lib/python3.12/threading.py\", line 1153, in join\n",
            "    self._wait_for_tstate_lock(timeout=max(timeout, 0))\n",
            "  File \"/home/naziruai/miniconda3/envs/deep_learning/lib/python3.12/threading.py\", line 1169, in _wait_for_tstate_lock\n",
            "    if lock.acquire(block, timeout):\n",
            "       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "KeyboardInterrupt\n"
          ]
        }
      ],
      "source": [
        "!python ethnic_classifier_gradio_app.py"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "odict_keys(['_conv_stem.weight', '_bn0.weight', '_bn0.bias', '_bn0.running_mean', '_bn0.running_var', '_bn0.num_batches_tracked', '_blocks.0._depthwise_conv.weight', '_blocks.0._bn1.weight', '_blocks.0._bn1.bias', '_blocks.0._bn1.running_mean', '_blocks.0._bn1.running_var', '_blocks.0._bn1.num_batches_tracked', '_blocks.0._se_reduce.weight', '_blocks.0._se_reduce.bias', '_blocks.0._se_expand.weight', '_blocks.0._se_expand.bias', '_blocks.0._project_conv.weight', '_blocks.0._bn2.weight', '_blocks.0._bn2.bias', '_blocks.0._bn2.running_mean', '_blocks.0._bn2.running_var', '_blocks.0._bn2.num_batches_tracked', '_blocks.1._expand_conv.weight', '_blocks.1._bn0.weight', '_blocks.1._bn0.bias', '_blocks.1._bn0.running_mean', '_blocks.1._bn0.running_var', '_blocks.1._bn0.num_batches_tracked', '_blocks.1._depthwise_conv.weight', '_blocks.1._bn1.weight', '_blocks.1._bn1.bias', '_blocks.1._bn1.running_mean', '_blocks.1._bn1.running_var', '_blocks.1._bn1.num_batches_tracked', '_blocks.1._se_reduce.weight', '_blocks.1._se_reduce.bias', '_blocks.1._se_expand.weight', '_blocks.1._se_expand.bias', '_blocks.1._project_conv.weight', '_blocks.1._bn2.weight', '_blocks.1._bn2.bias', '_blocks.1._bn2.running_mean', '_blocks.1._bn2.running_var', '_blocks.1._bn2.num_batches_tracked', '_blocks.2._expand_conv.weight', '_blocks.2._bn0.weight', '_blocks.2._bn0.bias', '_blocks.2._bn0.running_mean', '_blocks.2._bn0.running_var', '_blocks.2._bn0.num_batches_tracked', '_blocks.2._depthwise_conv.weight', '_blocks.2._bn1.weight', '_blocks.2._bn1.bias', '_blocks.2._bn1.running_mean', '_blocks.2._bn1.running_var', '_blocks.2._bn1.num_batches_tracked', '_blocks.2._se_reduce.weight', '_blocks.2._se_reduce.bias', '_blocks.2._se_expand.weight', '_blocks.2._se_expand.bias', '_blocks.2._project_conv.weight', '_blocks.2._bn2.weight', '_blocks.2._bn2.bias', '_blocks.2._bn2.running_mean', '_blocks.2._bn2.running_var', '_blocks.2._bn2.num_batches_tracked', '_blocks.3._expand_conv.weight', '_blocks.3._bn0.weight', '_blocks.3._bn0.bias', '_blocks.3._bn0.running_mean', '_blocks.3._bn0.running_var', '_blocks.3._bn0.num_batches_tracked', '_blocks.3._depthwise_conv.weight', '_blocks.3._bn1.weight', '_blocks.3._bn1.bias', '_blocks.3._bn1.running_mean', '_blocks.3._bn1.running_var', '_blocks.3._bn1.num_batches_tracked', '_blocks.3._se_reduce.weight', '_blocks.3._se_reduce.bias', '_blocks.3._se_expand.weight', '_blocks.3._se_expand.bias', '_blocks.3._project_conv.weight', '_blocks.3._bn2.weight', '_blocks.3._bn2.bias', '_blocks.3._bn2.running_mean', '_blocks.3._bn2.running_var', '_blocks.3._bn2.num_batches_tracked', '_blocks.4._expand_conv.weight', '_blocks.4._bn0.weight', '_blocks.4._bn0.bias', '_blocks.4._bn0.running_mean', '_blocks.4._bn0.running_var', '_blocks.4._bn0.num_batches_tracked', '_blocks.4._depthwise_conv.weight', '_blocks.4._bn1.weight', '_blocks.4._bn1.bias', '_blocks.4._bn1.running_mean', '_blocks.4._bn1.running_var', '_blocks.4._bn1.num_batches_tracked', '_blocks.4._se_reduce.weight', '_blocks.4._se_reduce.bias', '_blocks.4._se_expand.weight', '_blocks.4._se_expand.bias', '_blocks.4._project_conv.weight', '_blocks.4._bn2.weight', '_blocks.4._bn2.bias', '_blocks.4._bn2.running_mean', '_blocks.4._bn2.running_var', '_blocks.4._bn2.num_batches_tracked', '_blocks.5._expand_conv.weight', '_blocks.5._bn0.weight', '_blocks.5._bn0.bias', '_blocks.5._bn0.running_mean', '_blocks.5._bn0.running_var', '_blocks.5._bn0.num_batches_tracked', '_blocks.5._depthwise_conv.weight', '_blocks.5._bn1.weight', '_blocks.5._bn1.bias', '_blocks.5._bn1.running_mean', '_blocks.5._bn1.running_var', '_blocks.5._bn1.num_batches_tracked', '_blocks.5._se_reduce.weight', '_blocks.5._se_reduce.bias', '_blocks.5._se_expand.weight', '_blocks.5._se_expand.bias', '_blocks.5._project_conv.weight', '_blocks.5._bn2.weight', '_blocks.5._bn2.bias', '_blocks.5._bn2.running_mean', '_blocks.5._bn2.running_var', '_blocks.5._bn2.num_batches_tracked', '_blocks.6._expand_conv.weight', '_blocks.6._bn0.weight', '_blocks.6._bn0.bias', '_blocks.6._bn0.running_mean', '_blocks.6._bn0.running_var', '_blocks.6._bn0.num_batches_tracked', '_blocks.6._depthwise_conv.weight', '_blocks.6._bn1.weight', '_blocks.6._bn1.bias', '_blocks.6._bn1.running_mean', '_blocks.6._bn1.running_var', '_blocks.6._bn1.num_batches_tracked', '_blocks.6._se_reduce.weight', '_blocks.6._se_reduce.bias', '_blocks.6._se_expand.weight', '_blocks.6._se_expand.bias', '_blocks.6._project_conv.weight', '_blocks.6._bn2.weight', '_blocks.6._bn2.bias', '_blocks.6._bn2.running_mean', '_blocks.6._bn2.running_var', '_blocks.6._bn2.num_batches_tracked', '_blocks.7._expand_conv.weight', '_blocks.7._bn0.weight', '_blocks.7._bn0.bias', '_blocks.7._bn0.running_mean', '_blocks.7._bn0.running_var', '_blocks.7._bn0.num_batches_tracked', '_blocks.7._depthwise_conv.weight', '_blocks.7._bn1.weight', '_blocks.7._bn1.bias', '_blocks.7._bn1.running_mean', '_blocks.7._bn1.running_var', '_blocks.7._bn1.num_batches_tracked', '_blocks.7._se_reduce.weight', '_blocks.7._se_reduce.bias', '_blocks.7._se_expand.weight', '_blocks.7._se_expand.bias', '_blocks.7._project_conv.weight', '_blocks.7._bn2.weight', '_blocks.7._bn2.bias', '_blocks.7._bn2.running_mean', '_blocks.7._bn2.running_var', '_blocks.7._bn2.num_batches_tracked', '_blocks.8._expand_conv.weight', '_blocks.8._bn0.weight', '_blocks.8._bn0.bias', '_blocks.8._bn0.running_mean', '_blocks.8._bn0.running_var', '_blocks.8._bn0.num_batches_tracked', '_blocks.8._depthwise_conv.weight', '_blocks.8._bn1.weight', '_blocks.8._bn1.bias', '_blocks.8._bn1.running_mean', '_blocks.8._bn1.running_var', '_blocks.8._bn1.num_batches_tracked', '_blocks.8._se_reduce.weight', '_blocks.8._se_reduce.bias', '_blocks.8._se_expand.weight', '_blocks.8._se_expand.bias', '_blocks.8._project_conv.weight', '_blocks.8._bn2.weight', '_blocks.8._bn2.bias', '_blocks.8._bn2.running_mean', '_blocks.8._bn2.running_var', '_blocks.8._bn2.num_batches_tracked', '_blocks.9._expand_conv.weight', '_blocks.9._bn0.weight', '_blocks.9._bn0.bias', '_blocks.9._bn0.running_mean', '_blocks.9._bn0.running_var', '_blocks.9._bn0.num_batches_tracked', '_blocks.9._depthwise_conv.weight', '_blocks.9._bn1.weight', '_blocks.9._bn1.bias', '_blocks.9._bn1.running_mean', '_blocks.9._bn1.running_var', '_blocks.9._bn1.num_batches_tracked', '_blocks.9._se_reduce.weight', '_blocks.9._se_reduce.bias', '_blocks.9._se_expand.weight', '_blocks.9._se_expand.bias', '_blocks.9._project_conv.weight', '_blocks.9._bn2.weight', '_blocks.9._bn2.bias', '_blocks.9._bn2.running_mean', '_blocks.9._bn2.running_var', '_blocks.9._bn2.num_batches_tracked', '_blocks.10._expand_conv.weight', '_blocks.10._bn0.weight', '_blocks.10._bn0.bias', '_blocks.10._bn0.running_mean', '_blocks.10._bn0.running_var', '_blocks.10._bn0.num_batches_tracked', '_blocks.10._depthwise_conv.weight', '_blocks.10._bn1.weight', '_blocks.10._bn1.bias', '_blocks.10._bn1.running_mean', '_blocks.10._bn1.running_var', '_blocks.10._bn1.num_batches_tracked', '_blocks.10._se_reduce.weight', '_blocks.10._se_reduce.bias', '_blocks.10._se_expand.weight', '_blocks.10._se_expand.bias', '_blocks.10._project_conv.weight', '_blocks.10._bn2.weight', '_blocks.10._bn2.bias', '_blocks.10._bn2.running_mean', '_blocks.10._bn2.running_var', '_blocks.10._bn2.num_batches_tracked', '_blocks.11._expand_conv.weight', '_blocks.11._bn0.weight', '_blocks.11._bn0.bias', '_blocks.11._bn0.running_mean', '_blocks.11._bn0.running_var', '_blocks.11._bn0.num_batches_tracked', '_blocks.11._depthwise_conv.weight', '_blocks.11._bn1.weight', '_blocks.11._bn1.bias', '_blocks.11._bn1.running_mean', '_blocks.11._bn1.running_var', '_blocks.11._bn1.num_batches_tracked', '_blocks.11._se_reduce.weight', '_blocks.11._se_reduce.bias', '_blocks.11._se_expand.weight', '_blocks.11._se_expand.bias', '_blocks.11._project_conv.weight', '_blocks.11._bn2.weight', '_blocks.11._bn2.bias', '_blocks.11._bn2.running_mean', '_blocks.11._bn2.running_var', '_blocks.11._bn2.num_batches_tracked', '_blocks.12._expand_conv.weight', '_blocks.12._bn0.weight', '_blocks.12._bn0.bias', '_blocks.12._bn0.running_mean', '_blocks.12._bn0.running_var', '_blocks.12._bn0.num_batches_tracked', '_blocks.12._depthwise_conv.weight', '_blocks.12._bn1.weight', '_blocks.12._bn1.bias', '_blocks.12._bn1.running_mean', '_blocks.12._bn1.running_var', '_blocks.12._bn1.num_batches_tracked', '_blocks.12._se_reduce.weight', '_blocks.12._se_reduce.bias', '_blocks.12._se_expand.weight', '_blocks.12._se_expand.bias', '_blocks.12._project_conv.weight', '_blocks.12._bn2.weight', '_blocks.12._bn2.bias', '_blocks.12._bn2.running_mean', '_blocks.12._bn2.running_var', '_blocks.12._bn2.num_batches_tracked', '_blocks.13._expand_conv.weight', '_blocks.13._bn0.weight', '_blocks.13._bn0.bias', '_blocks.13._bn0.running_mean', '_blocks.13._bn0.running_var', '_blocks.13._bn0.num_batches_tracked', '_blocks.13._depthwise_conv.weight', '_blocks.13._bn1.weight', '_blocks.13._bn1.bias', '_blocks.13._bn1.running_mean', '_blocks.13._bn1.running_var', '_blocks.13._bn1.num_batches_tracked', '_blocks.13._se_reduce.weight', '_blocks.13._se_reduce.bias', '_blocks.13._se_expand.weight', '_blocks.13._se_expand.bias', '_blocks.13._project_conv.weight', '_blocks.13._bn2.weight', '_blocks.13._bn2.bias', '_blocks.13._bn2.running_mean', '_blocks.13._bn2.running_var', '_blocks.13._bn2.num_batches_tracked', '_blocks.14._expand_conv.weight', '_blocks.14._bn0.weight', '_blocks.14._bn0.bias', '_blocks.14._bn0.running_mean', '_blocks.14._bn0.running_var', '_blocks.14._bn0.num_batches_tracked', '_blocks.14._depthwise_conv.weight', '_blocks.14._bn1.weight', '_blocks.14._bn1.bias', '_blocks.14._bn1.running_mean', '_blocks.14._bn1.running_var', '_blocks.14._bn1.num_batches_tracked', '_blocks.14._se_reduce.weight', '_blocks.14._se_reduce.bias', '_blocks.14._se_expand.weight', '_blocks.14._se_expand.bias', '_blocks.14._project_conv.weight', '_blocks.14._bn2.weight', '_blocks.14._bn2.bias', '_blocks.14._bn2.running_mean', '_blocks.14._bn2.running_var', '_blocks.14._bn2.num_batches_tracked', '_blocks.15._expand_conv.weight', '_blocks.15._bn0.weight', '_blocks.15._bn0.bias', '_blocks.15._bn0.running_mean', '_blocks.15._bn0.running_var', '_blocks.15._bn0.num_batches_tracked', '_blocks.15._depthwise_conv.weight', '_blocks.15._bn1.weight', '_blocks.15._bn1.bias', '_blocks.15._bn1.running_mean', '_blocks.15._bn1.running_var', '_blocks.15._bn1.num_batches_tracked', '_blocks.15._se_reduce.weight', '_blocks.15._se_reduce.bias', '_blocks.15._se_expand.weight', '_blocks.15._se_expand.bias', '_blocks.15._project_conv.weight', '_blocks.15._bn2.weight', '_blocks.15._bn2.bias', '_blocks.15._bn2.running_mean', '_blocks.15._bn2.running_var', '_blocks.15._bn2.num_batches_tracked', '_conv_head.weight', '_bn1.weight', '_bn1.bias', '_bn1.running_mean', '_bn1.running_var', '_bn1.num_batches_tracked', '_fc.weight', '_fc.bias'])\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipykernel_6818/1891171929.py:1: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  state_dict = torch.load('efficientnetb0_weights.pth', map_location='cpu')\n"
          ]
        }
      ],
      "source": [
        "state_dict = torch.load('efficientnetb0_weights.pth', map_location='cpu')\n",
        "print(state_dict.keys())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "deep_learning",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.8"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
